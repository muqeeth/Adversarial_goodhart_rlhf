# Configuration for load_and_eval.py

# --- Model Names/Paths ---
ref_model_name: EleutherAI/pythia-6.9b-deduped # The base model used for PPL calculation
gold_model_name: cleanrl/EleutherAI_pythia-6.9b-deduped__reward__tldr # The reward model (Judge Model)
gold_tokenizer_name: EleutherAI/pythia-6.9b-deduped

# --- Dataset --- #
dataset_name: AdversarialRLHF/rloo_pythia410m_tldr6.9b_rm410mdata_mergedsft_prefix_nokl_full_eval-dataset # Name of the dataset generated by generate_for_eval.py
dataset_split: validation
# --- Evaluation Parameters ---
batch_size: 256
torch_dtype: bfloat16

# --- Development/Debugging --- #
sanity_check: false 
wandb_run_id: rloo_pythia410m_tldr6.9b_rm410mdata_eval-dataset
# Configuration for load_and_eval.py

# --- Model Names/Paths ---
model_name_or_path: "path/to/your/finetuned_model_or_checkpoint_folder" # The model/adapter checkpoint folder to evaluate
ref_model_name: "path/to/your/base_or_reference_model"          # The base model used for PPL calculation
gold_model_name: "weqweasdas/reward-model-deberta-v3-large" # The reward model (Judge Model)

# --- Dataset --- #
dataset_path: "path/to/your/model_or_checkpoint_folder/_generations" # Path to the dataset generated by generate_for_eval.py

# --- Evaluation Parameters ---
batch_size: 16
torch_dtype: "auto"

# --- Development/Debugging --- #
sanity_check: false 
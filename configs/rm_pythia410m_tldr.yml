output_dir: rm_pythia410m_tldr
hub_model_id: mnoukhov/pythia410m-rm-tldr
push_to_hub: True
model_name_or_path: mnoukhov/pythia410m-sft-tldr
dataset_name: mnoukhov/summarize_from_feedback_oai_preprocessing_1706381144_relabel_pythia1b
dataset_eval_split: validation
learning_rate: 1.0e-5
lr_scheduler_type: cosine
fp16: True
gradient_accumulation_steps: 8
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
num_train_epochs: 1
max_length: 640
## peft
use_peft: False
# lora_r: 16
# lora_alpha: 32
# lora_dropout: 0.
# lora_task_type: SEQ_CLS
gradient_checkpointing: False
## save strategy
evaluation_strategy: "steps"
eval_steps: 0.2
save_strategy: steps
save_steps: 0.2
hub_strategy: all_checkpoints
logging_steps: 100
ddp_find_unused_parameters: False

